<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>学习爬虫</title>
    <link href="/2022/05/25/%E5%AD%A6%E4%B9%A0%E7%88%AC%E8%99%AB/"/>
    <url>/2022/05/25/%E5%AD%A6%E4%B9%A0%E7%88%AC%E8%99%AB/</url>
    
    <content type="html"><![CDATA[<p>​<br>1. </p><p>爬虫在使用场景中的类型：</p><p>通用爬虫：抓取系统重要组成部分，抓取的是一整张页面数据。</p><p>聚焦爬虫：在通用爬虫的基础上，抓取页面的局部内容。</p><p>增量式爬虫：检测网站中数据更新的情况，只会抓取网站中最新更新的数据。</p><p>反爬机制与反反爬策略对立</p><p>robots.txt协议：规定了网站中哪些数据可以被爬虫爬取哪些不行。</p><p>哔哩哔哩的robots.txt协议</p><p>http与https协议</p><p>http协议：服务器与客户端进行数据交互的一种形式。</p><p>https协议：安全的超文本传输协议。</p><p>重要的头信息：</p><p>1.请求头</p><p>User-Agent:请求载体的身份标识</p><p>-Connection:请求完毕后，是断开连接还是保持连接。</p><p>2.回应头</p><p>Connection-Type:服务器响应会客户端的数据类型</p><p>加密方式</p><p>-对称密钥加密：对称密钥加密是双方使用相同的密钥，必须以绝对安全的形式传送密钥才能保证安全。若果密钥泄露，加密数据将受到威胁。</p><p>-非对称密钥加密：</p><p>1、乙方生成一对密钥（公钥和私钥）并将公钥向其它方公开。</p><p>2、得到该公钥的甲方使用该密钥对机密信息进行加密后再发送给乙方。</p><p>3、乙方再用自己保存的另一把专用密钥（私钥）对加密后的信息进行解密。乙方只能用其专用密钥（私钥）解密由对应的公钥加密后的信息。</p><p>在传输过程中，即使攻击者截获了传输的密文，并得到了乙的公钥，也无法破解密文，因为只有乙的私钥才能解密密文。</p><p>反之亦然。</p><p>-证书密钥加密：多一个中间机构对服务端发的公钥进行认证，认证成功后对公钥进行数字签名（防伪）并封装到证书中发送给客户端。客户端对数字签名进行验证，确认是服务端发出的公钥。</p><ol start="2"><li>-urllib模块（少用）—不讲</li></ol><p>-requests模块</p><p>requests模块：python中原生的一款基于网络请求的模块。</p><p>作用：模拟浏览器发请求。</p><p>如何使用：</p><ul><li><p>指定url</p></li><li><p>发起请求（get,post）</p></li><li><p>获取响应数据</p></li><li><p>持久化存储</p></li></ul><p>环境安装：</p><p>pip install request</p><p>import requests</p><h1 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h1><p>url&#x3D;’<a href="https://www.bilibili.com/&#39;">https://www.bilibili.com/&#39;</a></p><p>#发起请求,get方法会返回一个响应对象<br>response &#x3D; requests.get(url&#x3D;url)</p><h1 id="获取响应数据-text返回发是字符串形式的响应数据"><a href="#获取响应数据-text返回发是字符串形式的响应数据" class="headerlink" title="获取响应数据,text返回发是字符串形式的响应数据"></a>获取响应数据,text返回发是字符串形式的响应数据</h1><p>page_text &#x3D; response.text<br>print(page_text)</p><h1 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h1><p>with open(‘.&#x2F;bilibili.html’,’w’,encoding&#x3D;’utf-8’) as fp:<br>    fp.write(page_text)</p><p>print(‘end!’)</p><p>3.一些实例<br>第一实例：爬取搜狗搜索到的页面<br>#爬取搜狗搜索到的页面<br>#反爬： UA识别：User-Agent(请求载体的身份标识)</p><h1 id="门户网站的服务器会检测对应请求的载体身份标识，如果检测到请求的载体身份标识为某一款浏览器，说明该请求是一个正常请求。否则服务器端可能拒绝该请请求。"><a href="#门户网站的服务器会检测对应请求的载体身份标识，如果检测到请求的载体身份标识为某一款浏览器，说明该请求是一个正常请求。否则服务器端可能拒绝该请请求。" class="headerlink" title="门户网站的服务器会检测对应请求的载体身份标识，如果检测到请求的载体身份标识为某一款浏览器，说明该请求是一个正常请求。否则服务器端可能拒绝该请请求。"></a>门户网站的服务器会检测对应请求的载体身份标识，如果检测到请求的载体身份标识为某一款浏览器，说明该请求是一个正常请求。否则服务器端可能拒绝该请请求。</h1><h1 id="反反爬：UA伪装：对UA进行伪装成浏览器发出的请求"><a href="#反反爬：UA伪装：对UA进行伪装成浏览器发出的请求" class="headerlink" title="反反爬：UA伪装：对UA进行伪装成浏览器发出的请求"></a>反反爬：UA伪装：对UA进行伪装成浏览器发出的请求</h1><p>import requests</p><h1 id="指定url-1"><a href="#指定url-1" class="headerlink" title="指定url"></a>指定url</h1><h1 id="UA伪装"><a href="#UA伪装" class="headerlink" title="UA伪装"></a>UA伪装</h1><p>headers&#x3D;{<br>    ‘User-Agent’:’Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko&#x2F;20100101 Firefox&#x2F;99.0’<br>}<br>url&#x3D;’<a href="https://www.sogou.com/web?&#39;">https://www.sogou.com/web?&#39;</a></p><h1 id="处理url携带的参数：封装到字典中"><a href="#处理url携带的参数：封装到字典中" class="headerlink" title="处理url携带的参数：封装到字典中"></a>处理url携带的参数：封装到字典中</h1><p>kw&#x3D;input(‘enter a word:’)<br>param&#x3D;{<br>    ‘query’:kw<br>}</p><h1 id="对指定的url发起的请求对应的url是携带参数的，并且请求过程中处理了参数"><a href="#对指定的url发起的请求对应的url是携带参数的，并且请求过程中处理了参数" class="headerlink" title="对指定的url发起的请求对应的url是携带参数的，并且请求过程中处理了参数"></a>对指定的url发起的请求对应的url是携带参数的，并且请求过程中处理了参数</h1><p>response &#x3D; requests.get(url&#x3D;url,params&#x3D;param,headers&#x3D;headers)<br>page_text&#x3D;response.text<br>fileName&#x3D;kw+’.html’<br>with open(fileName,’w’,encoding&#x3D;’utf-8’) as fp:<br>    fp.write(page_text)<br>print(fileName,’保存成功！’)</p><p>简单的反爬机制：</p><p>UA检测：</p><p>首先是浏览器标识（UA）：可以使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件，从而判断用户是使用电脑浏览还是手机浏览，让网页作出自动的适应。 设置成哪个（Android、iphone、ipad和电脑）就相当于用哪种设备浏览网页。</p><p>所以可以简单的通过UA检测识别出哪些是通过浏览器发出请求，哪些是通过爬虫发出请求。</p><p>相应的简单的反反爬机制：</p><p>UA伪装：让爬虫的身份标识伪装成某一浏览器的身份标识。即将对应的身份标识封装到一个字典中。</p><p>第二实例：爬取百度翻译<br>先来了解一下用于网页局部刷新的ajax（阿贾克斯请求）。</p><p>首先Ajax 是浏览器提供的一套方法，可以实现页面无刷新更新数据，实现局部更新，提高用户浏览网站应用的体验。</p><p>在network中的XHR找到对应的ajax请求，是一个post请求（携带有参数）</p><p>import requests<br>import json</p><h1 id="1-指定url"><a href="#1-指定url" class="headerlink" title="1.指定url"></a>1.指定url</h1><p>post_url&#x3D;’<a href="https://fanyi.baidu.com/sug&#39;">https://fanyi.baidu.com/sug&#39;</a></p><h1 id="2-进行UA伪装"><a href="#2-进行UA伪装" class="headerlink" title="2.进行UA伪装"></a>2.进行UA伪装</h1><p>headers&#x3D;{<br>    ‘User-Agent’:’Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko&#x2F;20100101 Firefox&#x2F;99.0’<br>}</p><h1 id="3-post请求参数处理（同get请求一致）"><a href="#3-post请求参数处理（同get请求一致）" class="headerlink" title="3.post请求参数处理（同get请求一致）"></a>3.post请求参数处理（同get请求一致）</h1><p>word&#x3D;input(‘输入你想要翻译的词语：’)<br>post_data&#x3D;{<br>    ‘kw’:word<br>}</p><h1 id="4-请求发送"><a href="#4-请求发送" class="headerlink" title="4.请求发送"></a>4.请求发送</h1><p>response &#x3D; requests.post(<br>    url&#x3D;post_url,data&#x3D;post_data,headers&#x3D;headers<br>)</p><h1 id="获取响应数据-json-方法返回的是obj（如果确认响应数据是json类型才能使用）"><a href="#获取响应数据-json-方法返回的是obj（如果确认响应数据是json类型才能使用）" class="headerlink" title="获取响应数据:json()方法返回的是obj（如果确认响应数据是json类型才能使用）"></a>获取响应数据:json()方法返回的是obj（如果确认响应数据是json类型才能使用）</h1><p>dic_obj&#x3D; response.json()</p><h1 id="持久化存储-1"><a href="#持久化存储-1" class="headerlink" title="持久化存储"></a>持久化存储</h1><p>fileName&#x3D;word+’.json’<br>fp&#x3D;open(fileName,’w’,encoding&#x3D;’utf-8’)<br>json.dump(dic_obj,fp&#x3D;fp,ensure_ascii&#x3D;False)</p><h1 id="最后的是禁止ascil编码，因为获取到的是中文"><a href="#最后的是禁止ascil编码，因为获取到的是中文" class="headerlink" title="最后的是禁止ascil编码，因为获取到的是中文"></a>最后的是禁止ascil编码，因为获取到的是中文</h1><p>简单爬取一下豆瓣的电影排名。</p><p>import json<br>import requests<br>url &#x3D; ‘<a href="https://movie.douban.com/j/chart/top_list&#39;">https://movie.douban.com/j/chart/top_list&#39;</a><br>#UA伪装<br>headers&#x3D;{<br>    ‘User-Agent’:’Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko&#x2F;20100101 Firefox&#x2F;99.0’<br>}<br>#配置参数<br>param&#x3D;{<br>     ‘type’:’24’,<br>    ‘interval_id’:’100:90’,<br>    ‘action’:’’,<br>    ‘start’:0,<br>    ‘limit’:40<br>}</p><p>resp &#x3D; requests.get(url&#x3D;url,params&#x3D;param,headers&#x3D;headers)</p><p>#永久化存储<br>page_obj &#x3D; resp.json()<br>fp&#x3D;open(‘.&#x2F;hh.json’,’w’,encoding&#x3D;’utf-8’)<br>json.dump(page_obj,fp&#x3D;fp,ensure_ascii&#x3D;False)<br>print(‘over!’)</p><p>这次运用到了参数。</p><p>RE：正则表达式</p><p>常用的元字符：</p><p>.：除换行符以外的任意字符</p><p>\w：字母，数字，下划线</p><p>\s：空白符</p><p>\d：数字</p><p>\n：换行符</p><p>\t：制表符</p><p>\W：非（字母，数字，下划线）</p><p>\D：非数字</p><p>\S：非空白符</p><p>a|b：匹配字符a或字符b</p><p>()：匹配括号内的表达式，也表示一个组</p><p>[…]：匹配字符组中的字符</p><p>[^…]：匹配除字符组中的所有字符</p><p>^：匹配字符串的开始</p><p>$：匹配字符串的结尾</p><p>量词：控制前面的元字符出现的次数</p><ul><li>：重复0次或多次</li></ul><ul><li>：重复一次或更多次</li></ul><p>？：重复0次或1次</p><p>{n}：重复n次</p><p>{n,}：重复n次或更多次</p><p>{n,m}：重复n到m次</p><p>贪婪匹配和惰性匹配</p><p>1.  .*  贪婪匹配</p><ol start="2"><li>.*?  惰性匹配</li></ol><p>正则代码简单用法</p><p>import re</p><h1 id="findall-匹配字符串中所有的符合正则的内容"><a href="#findall-匹配字符串中所有的符合正则的内容" class="headerlink" title="# findall:匹配字符串中所有的符合正则的内容"></a># findall:匹配字符串中所有的符合正则的内容</h1><h1 id="lst-x3D-re-findall-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’"><a href="#lst-x3D-re-findall-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’" class="headerlink" title="lst &#x3D; re.findall(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)"></a>lst &#x3D; re.findall(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)</h1><h1 id="print-lst"><a href="#print-lst" class="headerlink" title="print(lst)"></a>print(lst)</h1><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="finditer：匹配字符串中所有的内容【返回的是迭代器】-从迭代器中拿到内容需要-group"><a href="#finditer：匹配字符串中所有的内容【返回的是迭代器】-从迭代器中拿到内容需要-group" class="headerlink" title="# finditer：匹配字符串中所有的内容【返回的是迭代器】,从迭代器中拿到内容需要.group()"></a># finditer：匹配字符串中所有的内容【返回的是迭代器】,从迭代器中拿到内容需要.group()</h1><h1 id="it-x3D-re-finditer-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’"><a href="#it-x3D-re-finditer-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’" class="headerlink" title="it&#x3D;re.finditer(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)"></a>it&#x3D;re.finditer(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)</h1><h1 id="for-i-in-it"><a href="#for-i-in-it" class="headerlink" title="for i in it:"></a>for i in it:</h1><h1 id="print-i-group"><a href="#print-i-group" class="headerlink" title="print(i.group())"></a>print(i.group())</h1><h1 id="seach-找到一个结果就返回，返回的结果是match对象，拿数据需要-group"><a href="#seach-找到一个结果就返回，返回的结果是match对象，拿数据需要-group" class="headerlink" title="# seach,找到一个结果就返回，返回的结果是match对象，拿数据需要.group()"></a># seach,找到一个结果就返回，返回的结果是match对象，拿数据需要.group()</h1><h1 id="s-x3D-re-search-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’"><a href="#s-x3D-re-search-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’" class="headerlink" title="s &#x3D; re.search(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)"></a>s &#x3D; re.search(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)</h1><h1 id="print-s-group"><a href="#print-s-group" class="headerlink" title="print(s.group())"></a>print(s.group())</h1><h1 id="match-是从头开始匹配"><a href="#match-是从头开始匹配" class="headerlink" title="#match 是从头开始匹配"></a>#match 是从头开始匹配</h1><h1 id="s-x3D-re-match-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’"><a href="#s-x3D-re-match-r’-d-’-’我的电话号码是：10086，我女朋友的电话是：10010’" class="headerlink" title="s &#x3D; re.match(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)"></a>s &#x3D; re.match(r’\d+’,’我的电话号码是：10086，我女朋友的电话是：10010’)</h1><h1 id="print-s-group-1"><a href="#print-s-group-1" class="headerlink" title="print(s.group())"></a>print(s.group())</h1><h1 id="预加载正则表达式"><a href="#预加载正则表达式" class="headerlink" title="预加载正则表达式"></a>预加载正则表达式</h1><h1 id="P-lt-分组名字-gt-正则-可以单独从正则匹配的内容中进一步提取内容"><a href="#P-lt-分组名字-gt-正则-可以单独从正则匹配的内容中进一步提取内容" class="headerlink" title="(?P&lt;分组名字&gt;正则),可以单独从正则匹配的内容中进一步提取内容"></a>(?P&lt;分组名字&gt;正则),可以单独从正则匹配的内容中进一步提取内容</h1><p>s &#x3D; ‘’’</p><meta name="keywords" content="沪指,三大指数,收涨,上攻,半年线,指数,集体,东方证券,王丽颖,成交量配合" /><meta name="description" content="11月17日，三大指数集体收涨，沪指重返3500点。多空反复争夺沪指3500点，大盘有望上攻半年线吗？东方证券王丽颖认为，突破3500点需成交量配合及持续热点的出现；广发证券刘翀认为，年内指数或将维持弱平衡，建议关注小盘科技成长股；东方财富江峰认为，从行业角度挖掘跨年行情机会，目前指数缺乏整体性趋势。点击视频，一探究竟。" />'''obj = re.compile(r'<meta name="(?P<hh>.*?)" content="(?P<hhh>.*?)" />',re.S)# re.S 让.能匹配换行符ret = obj.finditer(s)for it in ret:    print(it.group('hh'))    print(it.group('hhh'))<p>爬取豆瓣电影排行榜</p><p>import requests<br>import re</p><h1 id="UA伪装-1"><a href="#UA伪装-1" class="headerlink" title="UA伪装"></a>UA伪装</h1><p>headers &#x3D; {‘User-Agent’: ‘Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko&#x2F;20100101 Firefox&#x2F;100.0’}</p><h1 id="url"><a href="#url" class="headerlink" title="url"></a>url</h1><p>url &#x3D; ‘<a href="https://movie.douban.com/chart&#39;">https://movie.douban.com/chart&#39;</a></p><h1 id="请求并存储网页源码"><a href="#请求并存储网页源码" class="headerlink" title="请求并存储网页源码"></a>请求并存储网页源码</h1><p>resp &#x3D; requests.get(url, headers&#x3D;headers)<br>page &#x3D; resp.text</p><h1 id="解析数据"><a href="#解析数据" class="headerlink" title="解析数据"></a>解析数据</h1><p>obj &#x3D; re.compile(r’<td valign="top">.<em>? <a href=".*?"  class="">(?P<name>.</em>?)&#x2F;.<em>?<p class="pl">(?P<b>.</em>?)</p>‘, re.S)<br>ret &#x3D; obj.finditer(page)</p><h1 id="打印数据"><a href="#打印数据" class="headerlink" title="打印数据"></a>打印数据</h1><p>n &#x3D; 1<br>for it in ret:<br>    print(n)<br>    print(it.group(‘name’).strip())<br>    # .strip  Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列<br>    print(it.group(‘b’))<br>    n+&#x3D;1<br>    print()</p><p>盗版电影天堂爬取<br>简单</p><p>import requests<br>import re</p><h1 id="url-1"><a href="#url-1" class="headerlink" title="url"></a>url</h1><p>url &#x3D; ‘https://dytt89.com/i/102986.html'</p><h1 id="请求并存储网页源码-1"><a href="#请求并存储网页源码-1" class="headerlink" title="请求并存储网页源码"></a>请求并存储网页源码</h1><p>requests.packages.urllib3.disable_warnings()</p><h1 id="将报错信息去掉"><a href="#将报错信息去掉" class="headerlink" title="将报错信息去掉"></a>将报错信息去掉</h1><p>resp &#x3D; requests.get(url, verify&#x3D;False)</p><h1 id="verify-x3D-False-可以移除SSL认证"><a href="#verify-x3D-False-可以移除SSL认证" class="headerlink" title="verify&#x3D;False 可以移除SSL认证"></a>verify&#x3D;False 可以移除SSL认证</h1><p>resp.encoding &#x3D; ‘gb2312’<br>#编码网页信息<br>page &#x3D; resp.text</p><h1 id="解析数据-1"><a href="#解析数据-1" class="headerlink" title="解析数据"></a>解析数据</h1><p>obj &#x3D; re.compile(r’<title>(?P<name>.*?)</title>‘, re.S)<br>ret &#x3D; obj.finditer(page)</p><h1 id="打印数据-1"><a href="#打印数据-1" class="headerlink" title="打印数据"></a>打印数据</h1><p>for it in ret:<br>    print(it.group(‘name’).strip())<br>    # .strip  Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列</p><p>print(‘OK!’)</p><p>遇到的问题</p><p>1.html编码问题，爬取的数据乱码。<br>遇到这种问题问题，我们可能会先在html标签中查找charset字符集。一般charset值有utf-8、gbk、gb2312、ascii等。</p><p>然后用encoding编码就行了。</p><p>2.ssl认证，无法读取数据问题<br>首先我们先认识什么是ssl认证。</p><p>SSL认证是指客户端到服务器端的认证。主要用来提供对用户和服务器的认证；对传送的数据进行加密和隐藏；确保数据在传送中不被改变。</p><p>而在python requests中可以: verify &#x3D; False 关闭ssl证书验证开关。</p><p>3.关闭ssl证书验证开关后数据会有几行报错信息<br>如果想把这些报错信息去掉，只需要在请求的地方加上requests.packages.urllib3.disable_warnings()</p><p>掌握了这些，我们看看中等难度的。</p><p>html中a标签表示超链接</p><p><a herf='url'>xxx</a></p><p>import requests<br>import re</p><h1 id="url-2"><a href="#url-2" class="headerlink" title="url"></a>url</h1><p>domain &#x3D; ‘<a href="https://dytt89.com/&#39;">https://dytt89.com/&#39;</a></p><h1 id="请求并存储网页源码-2"><a href="#请求并存储网页源码-2" class="headerlink" title="请求并存储网页源码"></a>请求并存储网页源码</h1><p>requests.packages.urllib3.disable_warnings()</p><h1 id="消除其中产生的错误代码"><a href="#消除其中产生的错误代码" class="headerlink" title="消除其中产生的错误代码"></a>消除其中产生的错误代码</h1><p>resp &#x3D; requests.get(domain, verify&#x3D;False)<br>resp.encoding &#x3D; ‘gb2312’</p><h1 id="指定字符集"><a href="#指定字符集" class="headerlink" title="指定字符集"></a>指定字符集</h1><p>obj1 &#x3D; re.compile(r’2022必看热片.<em>?<ul>(?P<ul>.</em>?)</ul>‘, re.S)</p><h1 id="确定主页面中自己想要的部分"><a href="#确定主页面中自己想要的部分" class="headerlink" title="确定主页面中自己想要的部分"></a>确定主页面中自己想要的部分</h1><p>obj2 &#x3D; re.compile(r”&lt;a href&#x3D;’(?P<href>.*?)’”, re.S)</p><h1 id="确定其中子页面的地址"><a href="#确定其中子页面的地址" class="headerlink" title="确定其中子页面的地址"></a>确定其中子页面的地址</h1><p>obj3 &#x3D; re.compile(r’◎片　　名(?P<name>.<em>?)<br />.</em>?<td style="WORD-WRAP: break-word" bgcolor="#fdfddf">‘<br>                  r’<a href="(?P<download>.*?)">‘,re.S)</p><h1 id="获取子页面中自己想要的内容"><a href="#获取子页面中自己想要的内容" class="headerlink" title="获取子页面中自己想要的内容"></a>获取子页面中自己想要的内容</h1><h1 id="拿到ul中的li"><a href="#拿到ul中的li" class="headerlink" title="拿到ul中的li"></a>拿到ul中的li</h1><p>result1 &#x3D; obj1.finditer(resp.text)<br>child_href_list &#x3D; []<br>for it in result1:<br>    ul &#x3D; it.group(‘ul’)</p><h1 id="提取子页面链接"><a href="#提取子页面链接" class="headerlink" title="提取子页面链接"></a>提取子页面链接</h1><pre><code class="hljs">result2 = obj2.finditer(ul)for itt in result2:    # 拼接子页面的url地址：域名 + 子页面地址    child_href = domain + itt.group(&#39;href&#39;).strip(&quot;/&quot;)    child_href_list.append(child_href)  # 把子页面保存起来</code></pre><h1 id="提取子页面内容"><a href="#提取子页面内容" class="headerlink" title="提取子页面内容"></a>提取子页面内容</h1><p>n &#x3D; 1<br>for href in child_href_list:<br>    print(n)<br>    requests.packages.urllib3.disable_warnings()<br>    # 获取子页面内容<br>    child_resp &#x3D; requests.get(href, verify&#x3D;False)<br>    child_resp.encoding &#x3D; ‘gb2312’<br>    # 保存子页面内容<br>    result3 &#x3D; obj3.search(child_resp.text)<br>    # 打印子页面内容<br>    print(result3.group(‘name’))<br>    print(result3.group(‘download’))<br>    n +&#x3D; 1<br>    print()</p><p>​</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/05/25/hello-world/"/>
    <url>/2022/05/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
